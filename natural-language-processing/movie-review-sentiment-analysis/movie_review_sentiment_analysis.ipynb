{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df504c6-24ac-4243-b42f-de39985aeaf8",
   "metadata": {},
   "source": [
    "**This project focuses on analyzing the sentiment of movie reviews using natural language processing (NLP) and machine learning techniques. The goal is to classify movie reviews, either positive or negative, providing insights into the overall reception of a movie.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1cbb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988b0058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset into dataframe\n",
    "movie_review_df = pd.read_csv('movie_review_dataset.tsv.zip', sep='\\t', compression='zip', header=0, quotechar='\"')\n",
    "\n",
    "# display first five rows to verify if data loaded properly\n",
    "movie_review_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f202e37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    12500\n",
       "1    12500\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by sentiment to get number of positive and negative reviews\n",
    "movie_review_df.groupby('sentiment')['id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b422e6",
   "metadata": {},
   "source": [
    "> **'0' represents a negative review, and '1' represents a positive review. There are 12500 negative reviews(0) and 12500 positive reviews(1).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b78d373f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating common methods to get the sentiment.\n",
    "Arguments will be passed to this method are text and type of the mode.\n",
    "Currently, it supports Textblob and Vader models.\n",
    "'''\n",
    "\n",
    "\n",
    "# method to get polarity from the text using different models\n",
    "def get_polarity_score(text, model):\n",
    "    if model == 'textblob':\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    elif(model=='vader'):\n",
    "        return vadersid.polarity_scores(text)['compound']\n",
    "\n",
    "# method to find sentiment from the text. 0 - negative review, 1- positive review\n",
    "def find_sentiment_using_model(text, model):\n",
    "    polarity_score = get_polarity_score(text,model)\n",
    "    if polarity_score>=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96ec461b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new column for sentiment using textblob\n",
    "movie_review_df['sentiment_using_textblob'] = movie_review_df['review'].apply(lambda x:find_sentiment_using_model(x,'textblob'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5724538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68524"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find accuracy using accuracy_score from sklearn\n",
    "accuracy_score(movie_review_df['sentiment'], movie_review_df['sentiment_using_textblob'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416169c",
   "metadata": {},
   "source": [
    "> **The accuracy of the model is 0.68524, which means textblob predicted review sentiment 68.52% of the time. Possible classes are positive and negative, and we can predict 1/number_of_class with random guessing, which represents 50% of the time, we can predict using random guessing. It implies that the textblob model is better than random guessing the provided dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012982e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment_using_textblob</th>\n",
       "      <th>sentiment_using_vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review  \\\n",
       "0  5814_8          1  With all this stuff going down at the moment w...   \n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...   \n",
       "3  3630_4          0  It must be assumed that those who praised this...   \n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...   \n",
       "\n",
       "   sentiment_using_textblob  sentiment_using_vader  \n",
       "0                         1                      0  \n",
       "1                         1                      1  \n",
       "2                         0                      0  \n",
       "3                         1                      0  \n",
       "4                         0                      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create object for the vader model analysis\n",
    "vadersid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# creating new column for sentiment using vader\n",
    "movie_review_df['sentiment_using_vader'] = movie_review_df['review'].apply(lambda x:find_sentiment_using_model(x,'vader'))\n",
    "\n",
    "# display first 5 rows to view the updated dataframe\n",
    "movie_review_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe93b5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69356"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find accuracy using accuracy_score from sklearn\n",
    "accuracy_score(movie_review_df['sentiment'], movie_review_df['sentiment_using_vader'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e3b75",
   "metadata": {},
   "source": [
    "> **The accuracy of the model is 0.69356, which means vader model predicted review sentiment 69.35% of the time. Possible classes are positive and negative, and we can predict 1/number_of_class with random guessing, which represents 50% of the time, we can predict using random guessing. It implies that the vader model is better than random guessing the provided dataset. It also shows that the Vader model is slightly better than the textblob model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "077a62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating a method to clean the text for a custom model. \n",
    "This method does the following cleanups 1. Convert text to lowercase, \n",
    "2. Remove all punctuation and special characters,\n",
    "3.Remove English stop words and 4.stemming text\n",
    "'''\n",
    "\n",
    "# create object for stemming\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# get the english stop word list\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# method to clean up the text\n",
    "def model_preprocessor_cleaning(text):\n",
    "# convert text to lowercase    \n",
    "    lower_case_text = text.lower()\n",
    "# remove all punctuation and special characters    \n",
    "    alnum_only_text = re.sub('[^\\w\\s]','',lower_case_text)    \n",
    "# tokenzing the text for stemming and stop word removal    \n",
    "    word_tokens = word_tokenize(alnum_only_text)\n",
    "# removing the stop words    \n",
    "    tokens_without_stopwords = [word for word in word_tokens if not word in stop_words]\n",
    "# stemming text and joining back    \n",
    "    cleansed_text = (\" \").join([porter.stem(word) for word in tokens_without_stopwords])\n",
    "    return cleansed_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0034b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to store cleaned text\n",
    "movie_review_df['cleansed_review_text'] = movie_review_df['review'].apply(model_preprocessor_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df29ca5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    stuff go moment mj ive start listen music watc...\n",
       "1    classic war world timothi hine entertain film ...\n",
       "2    film start manag nichola bell give welcom inve...\n",
       "3    must assum prais film greatest film opera ever...\n",
       "4    superbl trashi wondrous unpretenti 80 exploit ...\n",
       "Name: cleansed_review_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display first few rows\n",
    "movie_review_df['cleansed_review_text'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f678e31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 92528)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new object for bag of words matrix transform\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# get bag of words matrix\n",
    "bag_of_words_matrix = count_vect.fit_transform(movie_review_df['cleansed_review_text'])\n",
    "\n",
    "# Display the dimensions\n",
    "bag_of_words_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d694efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dimensions\n",
    "movie_review_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59914dbe",
   "metadata": {},
   "source": [
    "> **Above result shows both original dataframe and bag_of_words_matrix has same number of rows(25000)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fa650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new object for term frequency-inverse document frequenct matrix\n",
    "tf_idf = TfidfVectorizer()\n",
    "\n",
    "# get tf-idf matrix\n",
    "tf_idf_matrix = tf_idf.fit_transform(movie_review_df['cleansed_review_text'])\n",
    "\n",
    "# Display the dimensions\n",
    "tf_idf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270f9001",
   "metadata": {},
   "source": [
    "> **Above result shows both bag_of_words_matrix and tf_idf_matrix  has same dimensions(25000, 92528)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4974c-efda-4285-938b-c6b2f802807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using train_test_split from sklearn, split\n",
    "the dataset into train and test sets. \n",
    "sentiment is the target that needs to be predicted, and\n",
    "the remaining columns are independent variables.\n",
    "The parameter test_size = 0.2 allocates 20% of data for training,\n",
    "and random_state=0  gives the same train and\n",
    "test sets across different execution\n",
    "'''\n",
    "# get independent variables\n",
    "X = movie_review_df.iloc[:,-1:]\n",
    "\n",
    "# get dependent variable\n",
    "y = movie_review_df.iloc[:,(1)]\n",
    "\n",
    "\n",
    "# split the dataset\n",
    "feature_train, feature_test, target_train, target_test =\\\n",
    "train_test_split(X ,y,test_size = 0.2, random_state = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e81a97-a1f4-425c-9996-a0a93d77ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new object for term frequency-inverse document frequenct matrix\n",
    "tf_idf = TfidfVectorizer(max_features=20000, ngram_range = (1,2))\n",
    "\n",
    "# get tf-idf matrix\n",
    "tf_idf_matrix_train = tf_idf.fit_transform(feature_train['cleansed_review_text'])\n",
    "\n",
    "# Display the dimensions\n",
    "tf_idf_matrix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b209ad-4b84-418f-805b-73346a4bb2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tf-idf matrix\n",
    "tf_idf_matrix_test = tf_idf.transform(feature_test['cleansed_review_text'])\n",
    "\n",
    "# Display the dimensions\n",
    "tf_idf_matrix_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7a198-c911-4b27-9c49-7a28a5027253",
   "metadata": {},
   "source": [
    "> **Fitting data helps models to learn mean and variance from the data, and transform uses the fitted data and applies the actual transformation to the features. The tf-idf vectorization model learns from the training data when we fit the data to the model. We want to keep the test data hidden away from the model. So the model will not learn from the test data. We apply the transform to the test dataset so that the test dataset will be in the usable format for the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac6fd6-22ed-49b4-820e-fb514d684d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create instance of logisticregression\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "# train the model using training data\n",
    "logistic_regression.fit(tf_idf_matrix_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb832f-5b68-46bc-9061-8d0d12293471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for test dataset\n",
    "logit_predictions = logistic_regression.predict(tf_idf_matrix_test)\n",
    "logit_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7ff509-45f6-4cd8-988d-6dbf0894ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creating a method to evaluate the model performance. \n",
    "Performance metrics such as accuracy_score, confusion_matrix,\n",
    "precision_score, recall_score, and f1_score are calculated in this method. \n",
    "accuracy_score - The accuracy tells us how often we can expect \n",
    "the model to correctly predict an outcome out of the total\n",
    "number of times it made predictions.\n",
    "confusion_matrix - A confusion matrix often helps measure the classification models' performance.\n",
    "It aims to predict a categorical label for each input instance.\n",
    "precision_score - The precision score measures how well a classifier predicts the positive class\n",
    "recall_score - The recall score measures the model performance by correctly\n",
    "calculating the count of true positives out of all the actual positive values.\n",
    "f1_score -The F1 score helps to measure the model's accuracy\n",
    "'''\n",
    "\n",
    "def model_performance_metrices(target_test, predictions):\n",
    "    \n",
    "# find accuracy using accuracy_score from sklearn    \n",
    "    accuracy_score_val = accuracy_score(target_test, predictions)\n",
    "# print  accuracy score   \n",
    "    print('Accuracy score: %.3f\\n' % accuracy_score_val)\n",
    "    \n",
    "# Create confusion matrix    \n",
    "    cf_matrix = confusion_matrix(target_test, predictions)\n",
    "# Visualizing the confusion matrix \n",
    "    sns.heatmap(cf_matrix,\n",
    "            annot=True,\n",
    "            fmt='g',\n",
    "            xticklabels=['Positive_Review','Negative_Review'],\n",
    "            yticklabels=['Positive_Review','Negative_Review']\n",
    "           )\n",
    "# Set labels and titles    \n",
    "    plt.ylabel('Prediction',fontsize=13)\n",
    "    plt.xlabel('Actual',fontsize=13)\n",
    "    plt.title('Confusion Matrix',fontsize=17)\n",
    "# display the plot    \n",
    "    plt.show()\n",
    "    \n",
    "# find precision score using  sklearn  metrics  precision_score\n",
    "    precision_score_val = precision_score(target_test, predictions)\n",
    "# print precision score\n",
    "    print('\\nPrecision Score: %.3f' % precision_score_val)\n",
    "\n",
    "# find recall score using  sklearn  metrics recall_score\n",
    "    recall_score_val = recall_score(target_test, predictions)\n",
    "# print recall score\n",
    "    print('\\nRecall Score: %.3f' % recall_score_val)    \n",
    "\n",
    "# find f1 score using  sklearn  metrics f1_score\n",
    "    f1_score_val = f1_score(target_test, predictions)\n",
    "# print recall score\n",
    "    print('\\nF1 Score: %.3f' % f1_score_val)        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6812487-59e7-45cc-886c-dd6c6faa5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling method to get performance metrices\n",
    "model_performance_metrices(target_test, logit_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d30bd5-aa74-4f5f-a984-4fc188f63466",
   "metadata": {},
   "source": [
    "**Output comment**:\n",
    "\n",
    "> Accuracy Score - The above result shows that the logistic regression will predict the results correctly about 89.7% of the time for the given datasets.\n",
    "\n",
    "> Confusion Matrix - \n",
    "1. 224 true negative -  instances where the model correctly predicted the negative class.\n",
    "2. 291  false positive -instances where the model incorrectly predicted the positive class\n",
    "3. 2228 false negative - instances where the model incorrectly predicted the negative class\n",
    "4. 2257 true positve - instances where the model correctly predicted the positive class.\n",
    "\n",
    "> Precision Score - The precision score of the above model is 0.884. Higher precision means that there are fewer false positives when making predictions with the model, meaning more accurate results overall\n",
    "\n",
    "> Recall Score - The above model shows a 91% recall score, which is a good model. The recall score measures the model performance by correctly calculating the count of true positives out of all the actual positive values.\n",
    "\n",
    "> F1 Score - The F1 score for the above model is 0.896, which is an good model. The higher the F1 score better.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cf28e7-8678-48e9-8c91-e347bbc017cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "y_pred_proba = logistic_regression.predict_proba(tf_idf_matrix_test)[::,1]\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(target_test,  y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed85c6b9-4cd5-4f94-9944-282bcb6eeeb3",
   "metadata": {},
   "source": [
    "**Output comment:**\n",
    "\n",
    "> The more the ROC curve hugs the top left corner of the plot, the better the model does at classifying the data. The above ROC curve shows that the AUC is closer to 1, which implies that the model is an good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25119a-079c-4e7b-ad63-1efc2d664879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating instance for KNN\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Fitting k-nearest neighbors model\n",
    "knn.fit(tf_idf_matrix_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85644fb-8cd3-490b-978d-4e58461e5e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Knn prediction\n",
    "knn_predictions = knn.predict(tf_idf_matrix_test)\n",
    "knn_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac4e250-5025-48f3-b094-5deaa8e56a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling method to get performance metrices\n",
    "model_performance_metrices(target_test, knn_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0076fc2a-ea15-4513-8865-da6d049c2572",
   "metadata": {},
   "source": [
    "**Output comment**:\n",
    "\n",
    "> Accuracy Score - The above result shows that the KNN will predict the results correctly about 74.2% of the time for the given datasets.\n",
    "\n",
    "> Confusion Matrix - \n",
    "1. 408 true negative -  instances where the model correctly predicted the negative class.\n",
    "2. 709  false positive -instances where the model incorrectly predicted the positive class\n",
    "3. 2044 false negative - instances where the model incorrectly predicted the negative class\n",
    "4. 1839 true positve - instances where the model correctly predicted the positive class.\n",
    "\n",
    "> Precision Score - The precision score of the above model is 0.742. Higher precision means that there are fewer false positives when making predictions with the model, meaning more accurate results overall\n",
    "\n",
    "> Recall Score - The above model shows a 83% recall score, which is a good model. The recall score measures the model performance by correctly calculating the count of true positives out of all the actual positive values.\n",
    "\n",
    "> F1 Score - The F1 score for the above model is 0.785, which is an good model. The higher the F1 score better.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65399f8e-bf0a-4c00-8c6f-ab64aa919201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "y_pred_proba = knn.predict_proba(tf_idf_matrix_test)[::,1]\n",
    "\n",
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(target_test,  y_pred_proba)\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d94c0-5e33-4f1e-bdb1-3992e900051e",
   "metadata": {},
   "source": [
    "**Output comment:**\n",
    "\n",
    "> The more the ROC curve hugs the top left corner of the plot, the better the model does at classifying the data. The above ROC curve shows that the AUC is close to 0.75, which implies that the model is an good model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27cb08-53ad-487e-ab43-7bbb36732101",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "> Overall, the logistic regression model looks better than the KNN model for the given dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
